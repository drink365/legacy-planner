# pages/99_Copilot.py
import time
import streamlit as st
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import OpenAI, RateLimitError
from src.repos.leads_repo import log_event

st.set_page_config(page_title="æ°¸å‚³é¡§å• AI", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ§­ æ°¸å‚³é¡§å• AIï¼ˆgpt-5-nano å°ˆç”¨ï¼‰")

# --- å›ºå®šæ¨¡å‹ï¼šåªç”¨ gpt-5-nano ---
MODEL_NAME = "gpt-5-nano"

# --- ä½¿ç”¨è€…é«”é©—èˆ‡ç©©å®šæ€§è¨­å®š ---
COOLDOWN_SECONDS = 8      # å…©æ¬¡é€å‡ºé–“æœ€çŸ­é–“éš”ï¼Œé¿å…ç‹‚é»
HISTORY_TURNS = 6         # ä¿ç•™æœ€è¿‘å¹¾è¼ªå°è©±ï¼Œæ¸›å°‘ tokenã€é¿é™æµ
MAX_TOKENS = 512          # è¼¸å‡ºä¸Šé™ï¼Œé¿å…éé•·

SYS_PROMPT = (
    "ä½ æ˜¯æ°¸å‚³å®¶æ—è¾¦å…¬å®¤çš„é¡§å• AIã€‚ç”¨èªè¦æº«æš–ã€å°ˆæ¥­ã€ç°¡æ½”ã€‚"
    "èšç„¦å°ç£é«˜è³‡ç”¢æ—ç¾¤çš„é€€ä¼‘èˆ‡å‚³æ‰¿ï¼Œå›ç­”æ™‚è¦ï¼š\n"
    "1) å…ˆé‡æ¸…æƒ…å¢ƒï¼ˆå®¶åº­çµæ§‹ã€è³‡ç”¢é…ç½®ã€è·¨å¢ƒã€åå¥½ï¼‰\n"
    "2) æä¾› 3 æ­¥è¡Œå‹•å»ºè­°ï¼ˆå«ä¿å–®/ä¿¡è¨—/è´ˆèˆ‡çš„æ–¹å‘ï¼‰\n"
    "3) çµå°¾çµ¦ CTAï¼šä¸‹è¼‰é¡§å•å ±å‘Š / é ç´„è«®è©¢ã€‚\n"
)

# ---- åˆå§‹åŒ–ç‹€æ…‹ ----
if "chat" not in st.session_state:
    st.session_state.chat = []  # list[tuple(role, content)]
if "last_call_ts" not in st.session_state:
    st.session_state.last_call_ts = 0.0

# ---- é¡¯ç¤ºæ­·å²è¨Šæ¯ ----
for role, content in st.session_state.chat:
    with st.chat_message(role):
        st.markdown(content)

# ---- çµ„è£ messages ä¸¦è£åˆ‡æ­·å²ï¼ˆåƒ…ä¿ç•™æœ€è¿‘ HISTORY_TURNS è¼ªï¼‰ ----
def build_messages():
    messages = [{"role": "system", "content": SYS_PROMPT}]
    # åƒ…å–æœ€å¾Œ N è¼ª
    recent = st.session_state.chat[-(HISTORY_TURNS*2):] if HISTORY_TURNS > 0 else st.session_state.chat
    for r, c in recent:
        messages.append({"role": r, "content": c})
    return messages

# ---- æŒ‡æ•¸é€€é¿é‡è©¦ï¼ˆåƒ…é‡å° RateLimitErrorï¼‰----
@retry(
    reraise=True,
    stop=stop_after_attempt(5),                   # æœ€å¤š 5 æ¬¡
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type(RateLimitError),
)
def call_openai(client: OpenAI, messages):
    return client.chat.completions.create(
        model=MODEL_NAME,
        messages=messages,
        temperature=0.2,
        max_tokens=MAX_TOKENS,
    )

# ---- ä½¿ç”¨è€…è¼¸å…¥ ----
user_msg = st.chat_input("æƒ³å•çš„æƒ…å¢ƒæˆ–å•é¡Œï¼Œä¾‹å¦‚ï¼šå…ˆè´ˆèˆ‡é‚„æ˜¯ç”¨ä¿å–®ï¼Ÿæœ‰æµ·å¤–è³‡ç”¢è¦æ³¨æ„ä»€éº¼ï¼Ÿ")
if user_msg:
    # ç¯€æµï¼šé¿å…é€£é»é€ æˆé™æµ
    now = time.time()
    delta = now - st.session_state.last_call_ts
    if delta < COOLDOWN_SECONDS:
        with st.chat_message("assistant"):
            st.info(f"è¨Šæ¯å·²æ”¶åˆ°ï¼Œç‚ºé¿å…é™æµï¼Œè«‹ {int(COOLDOWN_SECONDS - delta)} ç§’å¾Œå†é€ ğŸ™")
        st.stop()

    st.session_state.chat.append(("user", user_msg))
    with st.chat_message("user"):
        st.markdown(user_msg)

    # æº–å‚™ OpenAI Clientï¼ˆå¯é¸ organizationï¼‰
    api_key = st.secrets["openai"]["api_key"]
    org     = st.secrets["openai"].get("organization", None)
    client_kwargs = {"api_key": api_key}
    if org:
        client_kwargs["organization"] = org
    client = OpenAI(**client_kwargs)

    messages = build_messages()

    with st.chat_message("assistant"):
        try:
            st.session_state.last_call_ts = time.time()  # è¨˜éŒ„ç¯€æµæ™‚é–“é»
            resp = call_openai(client, messages)
            ans = resp.choices[0].message.content
            st.markdown(ans)
            st.session_state.chat.append(("assistant", ans))
            log_event("chat", payload={"q": user_msg, "a": ans, "model": MODEL_NAME})

        except RateLimitError:
            st.error("ç›®å‰ gpt-5-nano è¼ƒå¿™æˆ–é”åˆ°é€Ÿç‡ä¸Šé™ï¼Œå·²è‡ªå‹•é‡è©¦æ•¸æ¬¡ã€‚è«‹ç¨å¾Œå†å•ä¸€æ¬¡ï¼Œæˆ–å°‡å•é¡Œæ•´åˆå¾Œå†é€ã€‚")
        except Exception as e:
            st.error("âš ï¸ ç„¡æ³•å–å¾—å›è¦†ã€‚è«‹ç¢ºèª `openai.api_key` æœ‰æ•ˆï¼Œä¸”å¸³æˆ¶å° gpt-5-nano å…·æœ‰ä½¿ç”¨æ¬Šã€‚")
            st.caption(f"æŠ€è¡“è¨Šæ¯ï¼š{e}")

st.divider()
st.info("å°æé†’ï¼šæ­¤å°è©±åƒ…ä¾›æ•™è‚²èˆ‡åˆæ­¥è¦åŠƒåƒè€ƒï¼Œå¯¦éš›æ–¹æ¡ˆä»éœ€é¡§å•å¯©è¦–ã€‚")
